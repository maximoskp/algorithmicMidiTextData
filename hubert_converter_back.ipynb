{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664f4966-f761-4e9c-a7b8-577bb6adbd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make dir\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "os.makedirs('midis/test', exist_ok=True)\n",
    "converter_script = 'musescore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32e0b15-30cf-430e-97d9-82476d3e8d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, xcb.\n",
      "\n",
      "Aborted (core dumped)\n",
      "qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, xcb.\n",
      "\n",
      "Aborted (core dumped)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m midi \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmidis/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file\n\u001b[1;32m      8\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/midis_wavs/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflac\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconverter_script\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmidi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m -o \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mwav\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/subprocess.py:1264\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/subprocess.py:2051\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 2051\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   2053\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/subprocess.py:2009\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2009\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   2011\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   2012\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   2013\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   2014\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "os.makedirs('data/midis_wavs', exist_ok=True)\n",
    "\n",
    "for file in os.listdir('data/midis'):\n",
    "    if 'mid' in file:\n",
    "        midi = 'midis/' + file\n",
    "        wav = \"data/midis_wavs/\" + file.replace('mid', 'flac')\n",
    "        subprocess.Popen(f'{converter_script} \"{midi}\" -o \"{wav}\"', shell=True).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62743a00-db43-4aec-b6d5-ba15268ae563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModel\n",
    "import torch\n",
    "\n",
    "model_id = 'ntu-spml/distilhubert'\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id, do_normalize=True, return_attention_mask=True\n",
    ")\n",
    "\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "model = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654f86e-dc2d-493f-935a-6be6715f33c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "path = 'C:\\\\Users\\\\konin\\\\PHd\\\\distilhubert encoder (13000 midis)\\\\midis'\n",
    "dataset = load_dataset('audiofolder', data_dir=path)\n",
    "\n",
    "# resample audio files to desired sample rate\n",
    "dataset = dataset.cast_column('audio', Audio(sampling_rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c75b25-167c-4ba1-8646-1d6d05df7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=feature_extractor.sampling_rate,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "dataset_encoded = dataset.map(\n",
    "    preprocess_function,\n",
    "    remove_columns=['audio'],\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    num_proc=1,\n",
    ")\n",
    "\n",
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be3025-0a2e-4a3c-aa73-f849b1d13e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for i in range(len(os.listdir(\"midis\\\\test\"))):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    t = torch.FloatTensor(dataset_encoded['test'][i]['input_values'] )\n",
    "    tt = t.view(1, t.shape[0])\n",
    "    \n",
    "    wav = dataset['test'][i]['audio']['path']\n",
    "\n",
    "    h = model(tt).last_hidden_state\n",
    "    h_mean = np.mean(h.squeeze().detach().numpy(), axis = 0)\n",
    "    \n",
    "    result_dict[wav.split('\\\\')[-1]] = h_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fdb6f-3123-4d49-9481-02aaf489e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(result_dict, orient='index', dtype=np.float32).reset_index()\n",
    "df.to_csv('13000 midis results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27450c3c-0385-47cb-84fe-1d1aaeae2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_new = pd.read_csv('13000 midis results.csv')\n",
    "df_new.iloc[:, 1:] = df_new.iloc[:, 1:].astype('float32')\n",
    "np_array = df_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d669a0-86c5-477a-b267-5651cba51ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12960, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = np_array[:, 0]\n",
    "features = np_array[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52fd82-9666-4b2d-8412-17f314807380",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "# Some plots\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `h` is your torch tensor\n",
    "h_numpy = h.squeeze().detach().numpy()\n",
    "\n",
    "# Create a time array for y-axis\n",
    "duration = t.shape[0] / sampling_rate\n",
    "time_seconds = np.linspace(0, duration, h_numpy.shape[0])\n",
    "\n",
    "# Create traces for each feature\n",
    "traces = []\n",
    "for i in range(h_numpy.shape[1]):\n",
    "    trace = go.Scatter(x=time_seconds, y=h_numpy[:, i], mode='lines', name=f'Feature {i}')\n",
    "    traces.append(trace)\n",
    "\n",
    "# Create the plot\n",
    "fig = go.Figure(data=traces)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Plot of Features Over Time',\n",
    "                  xaxis_title='Time (seconds)',\n",
    "                  yaxis_title='Feature Value')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e1bc4-07d7-4f68-a21b-dc33c5269925",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `data` is your dataset with shape (num_samples, 768)\n",
    "\n",
    "# Perform FFT\n",
    "fft_result = np.fft.fft(h_numpy, axis=0)\n",
    "frequencies = np.fft.fftfreq(h_numpy.shape[0], 1 / sampling_rate)\n",
    "\n",
    "# Plot the frequency spectrum\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(frequencies[:h_numpy.shape[0]//2], np.abs(fft_result[:h_numpy.shape[0]//2]))\n",
    "plt.title('Frequency Spectrum')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
